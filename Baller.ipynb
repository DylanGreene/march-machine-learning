{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will load in the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Two years will be predicted: 2016 and 2017. Each year has a dataset consisting of the following files:\n",
    "* RegularSeasonDetailedResults.csv\n",
    "  * This file identifies the game-by-game results for 32 seasons of historical data, from 1985 to 2015. Each year, it includes all games played from daynum 0 through 132 (which by definition is \"Selection Sunday,\" the day that tournament pairings are announced). Each row in the file represents a single game played.\n",
    "  * \"season\" - this is the year of the associated entry in seasons.csv (the year in which the final tournament occurs)\n",
    "  * \"daynum\" - this integer always ranges from 0 to 132, and tells you what day the game was played on. It represents an offset from the \"dayzero\" date in the \"seasons.csv\" file. For example, the first game in the file was daynum=20. Combined with the fact from the \"season.csv\" file that day zero was 10/29/1984, that means the first game was played 20 days later, or 11/18/1984. There are no teams that ever played more than one game on a given date, so you can use this fact if you need a unique key. In order to accomplish this uniqueness, we had to adjust one game's date. In March 2008, the SEC postseason tournament had to reschedule one game (Georgia-Kentucky) to a subsequent day, so Georgia had to actually play two games on the same day. In order to enforce this uniqueness, we moved the game date for the Georgia-Kentucky game back to its original date.\n",
    "  * \"wteam\" - this identifies the id number of the team that won the game, as listed in the \"teams.csv\" file. No matter whether the game was won by the home team or visiting team, \"wteam\" always identifies the winning team.\n",
    "  * \"wscore\" - this identifies the number of points scored by the winning team.  \n",
    "  * \"lteam\" - this identifies the id number of the team that lost the game.\n",
    "  * \"lscore\" - this identifies the number of points scored by the losing team.\n",
    "  * \"numot\" - this indicates the number of overtime periods in the game, an integer 0 or higher.\n",
    "  * \"wloc\" - this identifies the \"location\" of the winning team. If the winning team was the home team, this value will be \"H\". If the winning team was the visiting team, this value will be \"A\". If it was played on a neutral court, then this value will be \"N\". Sometimes it is unclear whether the site should be considered neutral, since it is near one team's home court, or even on their court during a tournament, but for this determination we have simply used the Kenneth Massey data in its current state, where the \"@\" sign is either listed with the winning team, the losing team, or neither team.\n",
    "  * \"wfgm\" - field goals made\n",
    "  * \"wfga\" - field goals attempted\n",
    "  * \"wfgm3\" - three pointers made\n",
    "  * \"wfga3\" - three pointers attempted\n",
    "  * \"wftm\" - free throws made\n",
    "  * \"wfta\" - free throws attempted\n",
    "  * \"wor\" - offensive rebounds\n",
    "  * \"wdr\" - defensive rebounds\n",
    "  * \"wast\" - assists\n",
    "  * \"wto\" - turnovers\n",
    "  * \"wstl\" - steals\n",
    "  * \"wblk\" - blocks\n",
    "  * \"wpf\" - personal fouls\n",
    "  \n",
    "* Seasons.csv\n",
    "  * This file identifies the seeds for all teams in each NCAA tournament, for all seasons of historical data. Thus, there are between 64-68 rows for each year, depending on the bracket structure.\n",
    "  * \"season\" - the year\n",
    "  * \"seed\" - this is a 3/4-character identifier of the seed, where the first character is either W, X, Y, or Z (identifying the region the team was in) and the next two digits (either 01, 02, ..., 15, or 16) tells you the seed within the region. For play-in teams, there is a fourth character (a or b) to further distinguish the seeds, since teams that face each other in the play-in games will have the same first three characters. For example, the first record in the file is seed W01, which means we are looking at the #1 seed in the W region (which we can see from the \"seasons.csv\" file was the East region). This seed is also referenced in the \"tourney_slots.csv\" file that tells us which bracket slots face which other bracket slots in which rounds.\n",
    "  * \"team\" - this identifies the id number of the team, as specified in the teams.csv file\n",
    "\n",
    "* Teams.csv\n",
    "* TourneyDetailedResults.csv\n",
    "* TourneySeeds.csv\n",
    "* TourneySlots.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in 2016 data\n",
    "\n",
    "# Import necessary tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "\n",
    "# Read in the file URL.\n",
    "season_results_file = 'Data/2017/RegularSeasonDetailedResults.csv'\n",
    "tourney_results_file = 'Data/2017/TourneyDetailedResults.csv'\n",
    "teams_file = 'Data/2017/Teams.csv'\n",
    "\n",
    "results = pd.read_csv(season_results_file)\n",
    "tourney_results = pd.read_csv(tourney_results_file)\n",
    "teams = pd.read_csv(teams_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select features to use and calculate season averages for each team\n",
    "\n",
    "def get_team_averages(teamid, year):\n",
    "    team_averages = dict()\n",
    "    season_results = results.loc[results['Season'] == year]\n",
    "\n",
    "    team_wins = season_results.loc[season_results['Wteam'] == teamid]\n",
    "    team_losses = season_results.loc[season_results['Lteam'] == teamid]\n",
    "    num_games = len(team_wins) + len(team_losses)\n",
    "    if not num_games: return None\n",
    "    percent_win = len(team_wins) / num_games\n",
    "    percent_loss = len(team_losses) / num_games\n",
    "\n",
    "    mean_win_results = team_wins.mean()\n",
    "    mean_loss_results = team_losses.mean()\n",
    "\n",
    "    # TODO Calculate entropy to determine which features to select \n",
    "    # TODO PCA to reduce dimensionality \n",
    "    \n",
    "    # Arbitrary features for now\n",
    "    if not len(team_wins):\n",
    "        mean_win_results = mean_win_results.fillna(0)\n",
    "        # Team\n",
    "        field_goal_percentage = mean_loss_results['Wfgm']/mean_loss_results['Wfga']\n",
    "        fg3pt_percentage = mean_loss_results['Wfgm3']/mean_loss_results['Wfga3']\n",
    "        ft_percentage = mean_loss_results['Wftm']/mean_loss_results['Wfta']\n",
    "        # Opp\n",
    "        opp_field_goal_percentage = mean_loss_results['Lfgm']/mean_loss_results['Lfga']\n",
    "        opp_fg3pt_percentage = mean_loss_results['Lfgm3']/mean_loss_results['Lfga3']\n",
    "        opp_ft_percentage = mean_loss_results['Lftm']/mean_loss_results['Lfta']\n",
    "    elif not len(team_losses):\n",
    "        mean_loss_results = mean_loss_results.fillna(0)\n",
    "        # Team\n",
    "        field_goal_percentage = mean_win_results['Lfgm']/mean_win_results['Lfga']\n",
    "        fg3pt_percentage = mean_win_results['Lfgm3']/mean_win_results['Lfga3']\n",
    "        ft_percentage = mean_win_results['Lftm']/mean_win_results['Lfta']\n",
    "        # Opp\n",
    "        opp_field_goal_percentage = mean_win_results['Wfgm']/mean_win_results['Wfga']\n",
    "        opp_fg3pt_percentage = mean_win_results['Wfgm3']/mean_win_results['Wfga3']\n",
    "        opp_ft_percentage = mean_win_results['Wftm']/mean_win_results['Wfta']\n",
    "    else:\n",
    "        # Team\n",
    "        field_goal_percentage = (mean_win_results['Wfgm']*percent_win)/(mean_win_results['Wfga']) + (mean_loss_results['Lfgm']*percent_loss)/(mean_loss_results['Lfga'])\n",
    "        fg3pt_percentage = (mean_win_results['Wfgm3']*percent_win)/(mean_win_results['Wfga3']) + (mean_loss_results['Lfgm3']*percent_loss)/(mean_loss_results['Lfga3'])\n",
    "        ft_percentage = (mean_win_results['Wftm']*percent_win)/(mean_win_results['Wfta']) + (mean_loss_results['Lftm']*percent_loss)/(mean_loss_results['Lfta'])\n",
    "        # Opp\n",
    "        opp_field_goal_percentage = (mean_win_results['Lfgm']*percent_win)/(mean_win_results['Lfga']) + (mean_loss_results['Wfgm']*percent_loss)/(mean_loss_results['Wfga'])\n",
    "        opp_fg3pt_percentage = (mean_win_results['Lfgm3']*percent_win)/(mean_win_results['Lfga3']) + (mean_loss_results['Wfgm3']*percent_loss)/(mean_loss_results['Wfga3'])\n",
    "        opp_ft_percentage = (mean_win_results['Lftm']*percent_win)/(mean_win_results['Lfta']) + (mean_loss_results['Wftm']*percent_loss)/(mean_loss_results['Wfta'])\n",
    "    \n",
    "    # Team\n",
    "    assists = (mean_win_results['Wast']*percent_win) + (mean_loss_results['Last']*percent_loss)\n",
    "    turnovers = (mean_win_results['Wto']*percent_win) + (mean_loss_results['Lto']*percent_loss)\n",
    "    # Opp\n",
    "    opp_assists = (mean_win_results['Last']*percent_win) + (mean_loss_results['Wast']*percent_loss)\n",
    "    opp_turnovers = (mean_win_results['Lto']*percent_win) + (mean_loss_results['Wto']*percent_loss)\n",
    "    \n",
    "    # TODO Win percent home\n",
    "    # TODO Win percent away\n",
    "    \n",
    "    return [field_goal_percentage, fg3pt_percentage, ft_percentage, assists, turnovers,\n",
    "           opp_field_goal_percentage, opp_fg3pt_percentage, opp_ft_percentage, opp_assists, opp_turnovers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create training data set (2003 through 2015)\n",
    "years = list(range(2003, 2015 + 1))\n",
    "\n",
    "def create_training_set():\n",
    "    training_set_features = []\n",
    "    training_set_class = []\n",
    "    for year in years:\n",
    "        team_stats = dict()\n",
    "        for team in teams['Team_Id']:\n",
    "            team_stats[team] = get_team_averages(team, year)\n",
    "        games = results.loc[results['Season'] == year]\n",
    "        for index, game in games.iterrows():\n",
    "            win_team = team_stats[game['Wteam']]\n",
    "            lose_team = team_stats[game['Lteam']]\n",
    "            game_differential = [w - l for w, l in zip(win_team, lose_team)]\n",
    "            training_set_features.append(game_differential)\n",
    "            training_set_class.append(0) # 1 Represents win\n",
    "            game_differential = [l - w for w, l in zip(win_team, lose_team)]\n",
    "            training_set_features.append(game_differential)\n",
    "            training_set_class.append(1) # 0 Represents loss\n",
    "    return [np.asarray(training_set_features), np.asarray(training_set_class)]\n",
    "        \n",
    "training_set = create_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create testing set (historical tournament data)\n",
    "\n",
    "def create_testing_set():\n",
    "    testing_set_features = []\n",
    "    testing_set_class = []\n",
    "    for year in years:\n",
    "        team_stats = dict()\n",
    "        for team in teams['Team_Id']:\n",
    "            team_stats[team] = get_team_averages(team, year)\n",
    "        games = tourney_results.loc[tourney_results['Season'] == year]\n",
    "        for index, game in games.iterrows():\n",
    "            win_team = team_stats[game['Wteam']]\n",
    "            lose_team = team_stats[game['Lteam']]\n",
    "            game_differential = [w - l for w, l in zip(win_team, lose_team)]\n",
    "            testing_set_features.append(game_differential)\n",
    "            testing_set_class.append(0) # Represents win\n",
    "    return [np.asarray(testing_set_features), np.asarray(testing_set_class)]\n",
    "        \n",
    "testing_set = create_testing_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If using MLP, scale data since it is sensitive to this\n",
    "\n",
    "def scale_sets():\n",
    "    from sklearn.preprocessing import StandardScaler  \n",
    "    scaler = StandardScaler()  \n",
    "    # Don't cheat - fit only on training data\n",
    "    scaler.fit(training_set[0])  \n",
    "    training_set[0] = scaler.transform(training_set[0])  \n",
    "    # apply same transformation to test data\n",
    "    testing_set[0] = scaler.transform(testing_set[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=True,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#classifier_model = GaussianNB()\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#classifier_model = LogisticRegression()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#classifier_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "classifier_model = MLPClassifier(hidden_layer_sizes=(15, 5), random_state=True)\n",
    "\n",
    "classifier_model.fit(training_set[0], training_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.681227863046\n"
     ]
    }
   ],
   "source": [
    "# Test the accuracy of the model on historical tournament data\n",
    "\n",
    "def test_model():\n",
    "    accuracy=[]\n",
    "    preds = classifier_model.predict(testing_set[0])\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    accuracy.append(np.mean(preds == testing_set[1]))\n",
    "\n",
    "    print(\"The accuracy is\", sum(accuracy)/len(accuracy))\n",
    "    \n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.43233593  0.56766407]\n"
     ]
    }
   ],
   "source": [
    "# Compare two teams average features to create new feature datastructure \n",
    "\n",
    "def predict(team1, team2, year):\n",
    "    team1_averages = get_team_averages(team1, year)\n",
    "    team2_averages = get_team_averages(team2, year)\n",
    "    game_differential = [w - l for w, l in zip(team1_averages, team2_averages)]\n",
    "    return classifier_model.predict_proba([game_differential])[0]\n",
    "\n",
    "print(predict(1323, 1437, 2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict brackets!\n",
    "\n",
    "# Read in the files for bracket structure and seeding\n",
    "tourney_slots_file = 'Data/2017/TourneySlots.csv'\n",
    "tourney_seeds_file = 'Data/2017/TourneySeeds.csv'\n",
    "tourney_slots = pd.read_csv(tourney_slots_file)\n",
    "tourney_seeds = pd.read_csv(tourney_seeds_file)\n",
    "\n",
    "def predict_bracket(year):\n",
    "    year_tourney_slots = tourney_slots.loc[tourney_slots['Season'] == year]\n",
    "    year_tourney_seeds = tourney_seeds.loc[tourney_seeds['Season'] == year]\n",
    "\n",
    "    predictions = dict()\n",
    "    for index, row in year_tourney_slots.iterrows():\n",
    "        team1 = row['Strongseed']\n",
    "        team2 = row['Weakseed']\n",
    "        \n",
    "        while team1 not in year_tourney_seeds['Seed'].tolist():\n",
    "            team1 = predictions[team1][0]\n",
    "        while team2 not in year_tourney_seeds['Seed'].tolist():\n",
    "            team2 = predictions[team2][0]\n",
    "            \n",
    "        team1_id = year_tourney_seeds.loc[year_tourney_seeds['Seed'] == team1]['Team'].values[0]\n",
    "        team2_id = year_tourney_seeds.loc[year_tourney_seeds['Seed'] == team2]['Team'].values[0]\n",
    "        team1_name = teams.loc[teams['Team_Id'] == team1_id]['Team_Name'].values[0]\n",
    "        team2_name = teams.loc[teams['Team_Id'] == team2_id]['Team_Name'].values[0]\n",
    "        \n",
    "        prediction = predict(team1_id, team2_id, year)\n",
    "        if prediction[0] >= 0.5:\n",
    "            predictions[row['Slot']] = [team1, team1_name, prediction[0]]\n",
    "        else:\n",
    "            predictions[row['Slot']] = [team2, team2_name, prediction[1]]\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R1W1': ['W01', 'Villanova', 0.89259254230360763],\n",
       " 'R1W2': ['W02', 'Duke', 0.71988413714100952],\n",
       " 'R1W3': ['W03', 'Baylor', 0.50018812744910246],\n",
       " 'R1W4': ['W13', 'ETSU', 0.50588185161564703],\n",
       " 'R1W5': ['W05', 'Virginia', 0.77808460702078819],\n",
       " 'R1W6': ['W06', 'SMU', 0.75368479281989753],\n",
       " 'R1W7': ['W10', 'Marquette', 0.57313540156289233],\n",
       " 'R1W8': ['W09', 'Virginia Tech', 0.51640853068424108],\n",
       " 'R1X1': ['X01', 'Gonzaga', 0.96987408833768751],\n",
       " 'R1X2': ['X02', 'Arizona', 0.66291009534290679],\n",
       " 'R1X3': ['X03', 'Florida St', 0.65158036543304321],\n",
       " 'R1X4': ['X04', 'West Virginia', 0.73350372076293091],\n",
       " 'R1X5': ['X05', 'Notre Dame', 0.5747858771718436],\n",
       " 'R1X6': ['X06', 'Maryland', 0.63925836029441263],\n",
       " 'R1X7': ['X07', \"St Mary's CA\", 0.69667357547691178],\n",
       " 'R1X8': ['X08', 'Northwestern', 0.75210532297216059],\n",
       " 'R1Y1': ['Y16a', 'NC Central', 0.55309555421743573],\n",
       " 'R1Y2': ['Y02', 'Louisville', 0.8193143360887335],\n",
       " 'R1Y3': ['Y03', 'Oregon', 0.73533054910651852],\n",
       " 'R1Y4': ['Y13', 'Vermont', 0.50446409515876489],\n",
       " 'R1Y5': ['Y05', 'Iowa St', 0.67799327989600799],\n",
       " 'R1Y6': ['Y06', 'Creighton', 0.60338278903361831],\n",
       " 'R1Y7': ['Y07', 'Michigan', 0.69424741395021838],\n",
       " 'R1Y8': ['Y09', 'Michigan St', 0.5138141120976133],\n",
       " 'R1Z1': ['Z01', 'North Carolina', 0.79065219220358229],\n",
       " 'R1Z2': ['Z02', 'Kentucky', 0.84696384130336222],\n",
       " 'R1Z3': ['Z03', 'UCLA', 0.94696162207872014],\n",
       " 'R1Z4': ['Z04', 'Butler', 0.56131790220027966],\n",
       " 'R1Z5': ['Z12', 'MTSU', 0.70863172878708047],\n",
       " 'R1Z6': ['Z06', 'Cincinnati', 0.75257930055461797],\n",
       " 'R1Z7': ['Z10', 'Wichita St', 0.73538085404991782],\n",
       " 'R1Z8': ['Z08', 'Arkansas', 0.79806946127091094],\n",
       " 'R2W1': ['W01', 'Villanova', 0.7612468943029026],\n",
       " 'R2W2': ['W02', 'Duke', 0.53895547951909772],\n",
       " 'R2W3': ['W06', 'SMU', 0.75565779864300575],\n",
       " 'R2W4': ['W05', 'Virginia', 0.71378974268595274],\n",
       " 'R2X1': ['X01', 'Gonzaga', 0.87435146534193153],\n",
       " 'R2X2': ['X07', \"St Mary's CA\", 0.67725613130352003],\n",
       " 'R2X3': ['X03', 'Florida St', 0.73221365169627306],\n",
       " 'R2X4': ['X04', 'West Virginia', 0.54236350624672092],\n",
       " 'R2Y1': ['Y16a', 'NC Central', 0.70487361489612788],\n",
       " 'R2Y2': ['Y02', 'Louisville', 0.58048569540925143],\n",
       " 'R2Y3': ['Y03', 'Oregon', 0.57909462892828767],\n",
       " 'R2Y4': ['Y05', 'Iowa St', 0.51593319589650199],\n",
       " 'R2Z1': ['Z01', 'North Carolina', 0.59127072710435713],\n",
       " 'R2Z2': ['Z10', 'Wichita St', 0.71772994638803667],\n",
       " 'R2Z3': ['Z03', 'UCLA', 0.63361134376248462],\n",
       " 'R2Z4': ['Z12', 'MTSU', 0.62569545495090628],\n",
       " 'R3W1': ['W05', 'Virginia', 0.54510894898832141],\n",
       " 'R3W2': ['W06', 'SMU', 0.69916947849696909],\n",
       " 'R3X1': ['X01', 'Gonzaga', 0.79179581273712785],\n",
       " 'R3X2': ['X07', \"St Mary's CA\", 0.62619659850584908],\n",
       " 'R3Y1': ['Y05', 'Iowa St', 0.51735955858934923],\n",
       " 'R3Y2': ['Y03', 'Oregon', 0.58110761755783424],\n",
       " 'R3Z1': ['Z12', 'MTSU', 0.6348038808661518],\n",
       " 'R3Z2': ['Z03', 'UCLA', 0.53275610004584661],\n",
       " 'R4W1': ['W06', 'SMU', 0.51288428796528129],\n",
       " 'R4X1': ['X01', 'Gonzaga', 0.76443454754754081],\n",
       " 'R4Y1': ['Y03', 'Oregon', 0.61271034715393846],\n",
       " 'R4Z1': ['Z03', 'UCLA', 0.63650085033193682],\n",
       " 'R5WX': ['X01', 'Gonzaga', 0.78679167612686896],\n",
       " 'R5YZ': ['Z03', 'UCLA', 0.65686439238534999],\n",
       " 'R6CH': ['X01', 'Gonzaga', 0.65393304200588065],\n",
       " 'W11': ['W11b', 'USC', 0.61496484450358602],\n",
       " 'W16': ['W16a', \"Mt St Mary's\", 0.50045973754065187],\n",
       " 'Y16': ['Y16a', 'NC Central', 0.82168218128410775],\n",
       " 'Z11': ['Z11a', 'Kansas St', 0.52134621753259824]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_bracket(2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
