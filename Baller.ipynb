{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will load in the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Two years will be predicted: 2016 and 2017. Each year has a dataset consisting of the following files:\n",
    "* RegularSeasonDetailedResults.csv\n",
    "  * This file identifies the game-by-game results for 32 seasons of historical data, from 1985 to 2015. Each year, it includes all games played from daynum 0 through 132 (which by definition is \"Selection Sunday,\" the day that tournament pairings are announced). Each row in the file represents a single game played.\n",
    "  * \"season\" - this is the year of the associated entry in seasons.csv (the year in which the final tournament occurs)\n",
    "  * \"daynum\" - this integer always ranges from 0 to 132, and tells you what day the game was played on. It represents an offset from the \"dayzero\" date in the \"seasons.csv\" file. For example, the first game in the file was daynum=20. Combined with the fact from the \"season.csv\" file that day zero was 10/29/1984, that means the first game was played 20 days later, or 11/18/1984. There are no teams that ever played more than one game on a given date, so you can use this fact if you need a unique key. In order to accomplish this uniqueness, we had to adjust one game's date. In March 2008, the SEC postseason tournament had to reschedule one game (Georgia-Kentucky) to a subsequent day, so Georgia had to actually play two games on the same day. In order to enforce this uniqueness, we moved the game date for the Georgia-Kentucky game back to its original date.\n",
    "  * \"wteam\" - this identifies the id number of the team that won the game, as listed in the \"teams.csv\" file. No matter whether the game was won by the home team or visiting team, \"wteam\" always identifies the winning team.\n",
    "  * \"wscore\" - this identifies the number of points scored by the winning team.  \n",
    "  * \"lteam\" - this identifies the id number of the team that lost the game.\n",
    "  * \"lscore\" - this identifies the number of points scored by the losing team.\n",
    "  * \"numot\" - this indicates the number of overtime periods in the game, an integer 0 or higher.\n",
    "  * \"wloc\" - this identifies the \"location\" of the winning team. If the winning team was the home team, this value will be \"H\". If the winning team was the visiting team, this value will be \"A\". If it was played on a neutral court, then this value will be \"N\". Sometimes it is unclear whether the site should be considered neutral, since it is near one team's home court, or even on their court during a tournament, but for this determination we have simply used the Kenneth Massey data in its current state, where the \"@\" sign is either listed with the winning team, the losing team, or neither team.\n",
    "  * \"wfgm\" - field goals made\n",
    "  * \"wfga\" - field goals attempted\n",
    "  * \"wfgm3\" - three pointers made\n",
    "  * \"wfga3\" - three pointers attempted\n",
    "  * \"wftm\" - free throws made\n",
    "  * \"wfta\" - free throws attempted\n",
    "  * \"wor\" - offensive rebounds\n",
    "  * \"wdr\" - defensive rebounds\n",
    "  * \"wast\" - assists\n",
    "  * \"wto\" - turnovers\n",
    "  * \"wstl\" - steals\n",
    "  * \"wblk\" - blocks\n",
    "  * \"wpf\" - personal fouls\n",
    "  \n",
    "* Seasons.csv\n",
    "  * This file identifies the seeds for all teams in each NCAA tournament, for all seasons of historical data. Thus, there are between 64-68 rows for each year, depending on the bracket structure.\n",
    "  * \"season\" - the year\n",
    "  * \"seed\" - this is a 3/4-character identifier of the seed, where the first character is either W, X, Y, or Z (identifying the region the team was in) and the next two digits (either 01, 02, ..., 15, or 16) tells you the seed within the region. For play-in teams, there is a fourth character (a or b) to further distinguish the seeds, since teams that face each other in the play-in games will have the same first three characters. For example, the first record in the file is seed W01, which means we are looking at the #1 seed in the W region (which we can see from the \"seasons.csv\" file was the East region). This seed is also referenced in the \"tourney_slots.csv\" file that tells us which bracket slots face which other bracket slots in which rounds.\n",
    "  * \"team\" - this identifies the id number of the team, as specified in the teams.csv file\n",
    "\n",
    "* Teams.csv\n",
    "* TourneyDetailedResults.csv\n",
    "* TourneySeeds.csv\n",
    "* TourneySlots.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in 2016 data\n",
    "\n",
    "# Import necessary tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "\n",
    "# Read in the file URL.\n",
    "season_results_file = 'Data/2017/RegularSeasonDetailedResults.csv'\n",
    "tourney_results_file = 'Data/2017/TourneyDetailedResults.csv'\n",
    "teams_file = 'Data/2017/Teams.csv'\n",
    "\n",
    "results = pd.read_csv(season_results_file)\n",
    "tourney_results = pd.read_csv(tourney_results_file)\n",
    "teams = pd.read_csv(teams_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select features to use and calculate season averages for each team\n",
    "\n",
    "def get_team_averages(teamid, year):\n",
    "    team_averages = dict()\n",
    "    season_results = results.loc[results['Season'] == year]\n",
    "\n",
    "    team_wins = season_results.loc[season_results['Wteam'] == teamid]\n",
    "    team_losses = season_results.loc[season_results['Lteam'] == teamid]\n",
    "    num_games = len(team_wins) + len(team_losses)\n",
    "    if not num_games: return None\n",
    "    percent_win = len(team_wins) / num_games\n",
    "    percent_loss = len(team_losses) / num_games\n",
    "\n",
    "    mean_win_results = team_wins.mean()\n",
    "    mean_loss_results = team_losses.mean()\n",
    "\n",
    "    # TODO Calculate entropy to determine which features to select \n",
    "    # TODO PCA to reduce dimensionality \n",
    "    \n",
    "    # Arbitrary features for now\n",
    "    if not len(team_wins):\n",
    "        mean_win_results = mean_win_results.fillna(0)\n",
    "        # Team\n",
    "        field_goal_percentage = mean_loss_results['Wfgm']/mean_loss_results['Wfga']\n",
    "        fg3pt_percentage = mean_loss_results['Wfgm3']/mean_loss_results['Wfga3']\n",
    "        ft_percentage = mean_loss_results['Wftm']/mean_loss_results['Wfta']\n",
    "        # Opp\n",
    "        opp_field_goal_percentage = mean_loss_results['Lfgm']/mean_loss_results['Lfga']\n",
    "        opp_fg3pt_percentage = mean_loss_results['Lfgm3']/mean_loss_results['Lfga3']\n",
    "        opp_ft_percentage = mean_loss_results['Lftm']/mean_loss_results['Lfta']\n",
    "    elif not len(team_losses):\n",
    "        mean_loss_results = mean_loss_results.fillna(0)\n",
    "        # Team\n",
    "        field_goal_percentage = mean_win_results['Lfgm']/mean_win_results['Lfga']\n",
    "        fg3pt_percentage = mean_win_results['Lfgm3']/mean_win_results['Lfga3']\n",
    "        ft_percentage = mean_win_results['Lftm']/mean_win_results['Lfta']\n",
    "        # Opp\n",
    "        opp_field_goal_percentage = mean_win_results['Wfgm']/mean_loss_results['Wfga']\n",
    "        opp_fg3pt_percentage = mean_win_results['Wfgm3']/mean_loss_results['Wfga3']\n",
    "        opp_ft_percentage = mean_win_results['Wftm']/mean_loss_results['Wfta']\n",
    "    else:\n",
    "        # Team\n",
    "        field_goal_percentage = (mean_win_results['Wfgm']*percent_win)/(mean_win_results['Wfga']) + (mean_loss_results['Lfgm']*percent_loss)/(mean_loss_results['Lfga'])\n",
    "        fg3pt_percentage = (mean_win_results['Wfgm3']*percent_win)/(mean_win_results['Wfga3']) + (mean_loss_results['Lfgm3']*percent_loss)/(mean_loss_results['Lfga3'])\n",
    "        ft_percentage = (mean_win_results['Wftm']*percent_win)/(mean_win_results['Wfta']) + (mean_loss_results['Lftm']*percent_loss)/(mean_loss_results['Lfta'])\n",
    "        # Opp\n",
    "        opp_field_goal_percentage = (mean_win_results['Lfgm']*percent_win)/(mean_win_results['Lfga']) + (mean_loss_results['Wfgm']*percent_loss)/(mean_loss_results['Wfga'])\n",
    "        opp_fg3pt_percentage = (mean_win_results['Lfgm3']*percent_win)/(mean_win_results['Lfga3']) + (mean_loss_results['Wfgm3']*percent_loss)/(mean_loss_results['Wfga3'])\n",
    "        opp_ft_percentage = (mean_win_results['Lftm']*percent_win)/(mean_win_results['Lfta']) + (mean_loss_results['Wftm']*percent_loss)/(mean_loss_results['Wfta'])\n",
    "    \n",
    "    # Team\n",
    "    assists = (mean_win_results['Wast']*percent_win) + (mean_loss_results['Last']*percent_loss)\n",
    "    turnovers = (mean_win_results['Wto']*percent_win) + (mean_loss_results['Lto']*percent_loss)\n",
    "    # Opp\n",
    "    opp_assists = (mean_win_results['Last']*percent_win) + (mean_loss_results['Wast']*percent_loss)\n",
    "    opp_turnovers = (mean_win_results['Lto']*percent_win) + (mean_loss_results['Wto']*percent_loss)\n",
    "    \n",
    "    # TODO Win percent home\n",
    "    # TODO Win percent away\n",
    "    \n",
    "    return [field_goal_percentage, fg3pt_percentage, ft_percentage, assists, turnovers,\n",
    "           opp_field_goal_percentage, opp_fg3pt_percentage, opp_ft_percentage, opp_assists, opp_turnovers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create training data set (2003 through 2015)\n",
    "years = list(range(2003, 2015 + 1))\n",
    "\n",
    "def create_training_set():\n",
    "    training_set_features = []\n",
    "    training_set_class = []\n",
    "    for year in years:\n",
    "        team_stats = dict()\n",
    "        for team in teams['Team_Id']:\n",
    "            team_stats[team] = get_team_averages(team, year)\n",
    "        games = results.loc[results['Season'] == year]\n",
    "        for index, game in games.iterrows():\n",
    "            win_team = team_stats[game['Wteam']]\n",
    "            lose_team = team_stats[game['Lteam']]\n",
    "            game_differential = [w - l for w, l in zip(win_team, lose_team)]\n",
    "            training_set_features.append(game_differential)\n",
    "            training_set_class.append(0) # 1 Represents win\n",
    "            game_differential = [l - w for w, l in zip(win_team, lose_team)]\n",
    "            training_set_features.append(game_differential)\n",
    "            training_set_class.append(1) # 0 Represents loss\n",
    "    return [np.asarray(training_set_features), np.asarray(training_set_class)]\n",
    "        \n",
    "training_set = create_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-257-f74436c47d93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclassifier_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dylan/anaconda3/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    175\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/home/dylan/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/dylan/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dylan/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier_model = GaussianNB()\n",
    "\n",
    "classifier_model.fit(training_set[0], training_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75820503  0.24179497]\n"
     ]
    }
   ],
   "source": [
    "# Compare two teams average features to create new feature datastructure \n",
    "\n",
    "def predict(team1, team2, year):\n",
    "    team1_averages = get_team_averages(team1, year)\n",
    "    team2_averages = get_team_averages(team2, year)\n",
    "    game_differential = [w - l for w, l in zip(team1_averages, team2_averages)]\n",
    "    return classifier_model.predict_proba([game_differential])[0]\n",
    "\n",
    "print(predict(1323, 1452, 2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the prediction for the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in 2017 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
